# LLM_Kernels
A high-performance implementation and verification toolkit for LLM kernels.
## MoE
- [x] Multiple communication strategies (All-to-All, AllGather)
- [x] Group GEMM acceleration
- [ ] Quantization (fp8, w4a8)
## MHA
- [ ] sage attention
